{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 01:52:49 WARN Utils: Your hostname, Rizwan.local resolves to a loopback address: 127.0.0.1; using 192.168.31.253 instead (on interface en0)\n",
      "24/09/15 01:52:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/15 01:52:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Spark-Ml\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with NA replacement\n",
    "df_flights = spark.read.csv(\"../../datasets/datasets-01/flights_small.csv\", header=\"true\", inferSchema=\"true\").replace(\"NA\", None)\n",
    "df_planes = spark.read.csv(\"../../datasets/datasets-01/planes.csv\", header=\"true\", inferSchema=\"true\").replace(\"NA\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare data\n",
    "df_planes = df_planes.drop(\"speed\").dropna()\n",
    "df_flights = df_flights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "df_planes = df_planes.withColumnRenamed(\"year\", \"manuf_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join flights and planes data\n",
    "model_data = df_flights.join(df_planes, on=\"tailnum\", how=\"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast relevent columns to integer\n",
    "columns_to_cast = [\"dep_time\", \"dep_delay\", \"arr_time\", \"air_time\", \"arr_delay\", \"hour\", \"minute\", \"manuf_year\"]\n",
    "for column in columns_to_cast:\n",
    "    model_data = model_data.withColumn(column, col(column).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "model_data = model_data.withColumn(\"plane_age\", col(\"year\") - col(\"manuf_year\"))\n",
    "model_data = model_data.withColumn(\"is_late\", col(\"arr_delay\") > 0)\n",
    "model_data = model_data.withColumn(\"label\", col(\"is_late\").cast(\"int\"))     # target col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove from where key features are missing\n",
    "required_columns = [\"arr_delay\", \"dep_delay\", \"arr_time\", \"manuf_year\"]\n",
    "model_data = model_data.dropna(subset=required_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimized method to count nulls in each column\n",
    "# null_counts = model_data.select(\n",
    "#     [count(when(col(c).isNull(), c)).alias(c) for c in model_data.columns]\n",
    "# )\n",
    "# # Show the null counts\n",
    "# null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns and their stages for the pipeline \n",
    "categorical_cols = [\"carrier\", \"dest\"]\n",
    "stages = []\n",
    "\n",
    "for column in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=column+\"_index\")                 \n",
    "    encoder = OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_encoded\")      \n",
    "    stages += [indexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features into a single vector\n",
    "features_cols = [\"dep_delay\", \"arr_delay\", \"arr_time\", \"month\", \"plane_age\"]\n",
    "\n",
    "assembler_inputs = [column+\"_encoded\" for column in categorical_cols] + features_cols       \n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")               \n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature engineering pipeline\n",
    "feature_pipleline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the model data\n",
    "fitted_pipeline = feature_pipleline.fit(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the model data using fitted pipeline (for training or testing)\n",
    "model_data_transformed = fitted_pipeline.transform(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+---------------+\n",
      "|carrier|carrier_index|carrier_encoded|\n",
      "+-------+-------------+---------------+\n",
      "|     US|          5.0| (10,[5],[1.0])|\n",
      "|     OO|          2.0| (10,[2],[1.0])|\n",
      "|     WN|          1.0| (10,[1],[1.0])|\n",
      "|     F9|          8.0| (10,[8],[1.0])|\n",
      "|     AA|         10.0|     (10,[],[])|\n",
      "|     AS|          0.0| (10,[0],[1.0])|\n",
      "|     HA|          9.0| (10,[9],[1.0])|\n",
      "|     B6|          6.0| (10,[6],[1.0])|\n",
      "|     VX|          7.0| (10,[7],[1.0])|\n",
      "|     UA|          4.0| (10,[4],[1.0])|\n",
      "|     DL|          3.0| (10,[3],[1.0])|\n",
      "+-------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data_transformed.select(\"carrier\", \"carrier_index\", \"carrier_encoded\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----+\n",
      "|features                                                      |label|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|(83,[7,11,78,79,80,81,82],[1.0,1.0,-7.0,-5.0,935.0,12.0,12.0])|0    |\n",
      "|(83,[0,29,78,79,80,81,82],[1.0,1.0,5.0,5.0,1505.0,1.0,17.0])  |1    |\n",
      "|(83,[7,10,78,79,80,81,82],[1.0,1.0,-2.0,2.0,1652.0,3.0,12.0]) |1    |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data_transformed.select(\"features\", \"label\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 01:54:02 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[tailnum: string, year: int, month: int, day: int, dep_time: int, dep_delay: int, arr_time: int, arr_delay: int, carrier: string, flight: int, origin: string, dest: string, air_time: int, distance: int, hour: int, minute: int, manuf_year: int, type: string, manufacturer: string, model: string, engines: int, seats: int, engine: string, plane_age: int, is_late: boolean, label: int, carrier_index: double, carrier_encoded: vector, dest_index: double, dest_encoded: vector, features: vector]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optonally cache the transformed data to speed up future operations\n",
    "model_data_transformed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "training, test = model_data_transformed.randomSplit([0.6, 0.4], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model\n",
    "model = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "# model.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with Cross Validation\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(model.regParam, np.arange(0, 0.1, 0.01))\\\n",
    "    .addGrid(model.elasticNetParam, [0, 1])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model evaluator\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up CrossValidator\n",
    "crossval = CrossValidator(\n",
    "    estimator=model,                    \n",
    "    estimatorParamMaps=param_grid,      \n",
    "    evaluator=evaluator,                \n",
    "    numFolds=5,                     \n",
    "    parallelism=4                     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 01:54:36 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/09/15 01:54:51 WARN BlockManager: Asked to remove block broadcast_2029_piece0, which does not exist\n"
     ]
    }
   ],
   "source": [
    "# Train the model using CrossValidator\n",
    "cv_model = crossval.fit(training)               # ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to save the pipeline and model\n",
    "# fitted_pipeline_path = \"model_artifacts/fitted_pipeline_model\"   \n",
    "# cv_model_path = \"model_artifacts/cv_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the fitted pipeline model to a path\n",
    "fitted_pipeline.write().overwrite().save(\"model-artifacts-01/fitted_pipeline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cross-validated model to a path\n",
    "cv_model.write().overwrite().save(\"model-artifacts-01/cv_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Area Under ROC : 1.0\n",
      "Testing Area Under ROC : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from CrossValidator\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Make prediction on the training data\n",
    "training_predictions = best_model.transform(training) \n",
    "\n",
    "# Evaluate training accuracy\n",
    "training_evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\", labelCol=\"label\")\n",
    "training_accuracy = training_evaluator.evaluate(training_predictions) \n",
    "print(f\"Training Area Under ROC : {training_accuracy}\")\n",
    "\n",
    "\n",
    "# Make prediction on the test data\n",
    "test_predictions = best_model.transform(test)  \n",
    "    \n",
    "# Evaluate tesing accuracy\n",
    "test_evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\", labelCol=\"label\")\n",
    "testing_accuracy = test_evaluator.evaluate(test_predictions) \n",
    "print(f\"Testing Area Under ROC : {testing_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 1.0\n",
      "Training precision : 0.9770655880103198\n",
      "Training recall : 0.9761904761904762\n",
      "Training F1 score : 0.9760241170229791\n",
      "Testing accuracy : 1.0\n",
      "Testing precision : 0.9736364410612954\n",
      "Testing recall : 0.9724745389485274\n",
      "Testing F1 score : 0.9722475814381987\n"
     ]
    }
   ],
   "source": [
    "# Initilize evaluators\n",
    "accuracy_eveluator = MulticlassClassificationEvaluator(metricName=\"accuracy\", labelCol=\"label\")\n",
    "precision_eveluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\", labelCol=\"label\")\n",
    "recall_eveluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\", labelCol=\"label\")\n",
    "f1_eveluator = MulticlassClassificationEvaluator(metricName=\"f1\", labelCol=\"label\")\n",
    "\n",
    "# Calculate metrices for training data \n",
    "training_accuracy = training_evaluator.evaluate(training_predictions) \n",
    "training_precision = precision_eveluator.evaluate(training_predictions) \n",
    "training_recall = recall_eveluator.evaluate(training_predictions) \n",
    "training_f1 = f1_eveluator.evaluate(training_predictions) \n",
    "\n",
    "print(f\"Training accuracy : {training_accuracy}\")\n",
    "print(f\"Training precision : {training_precision}\")\n",
    "print(f\"Training recall : {training_recall}\")\n",
    "print(f\"Training F1 score : {training_f1}\")\n",
    "\n",
    "\n",
    "# Calculate metrices for testing data \n",
    "testing_accuracy = training_evaluator.evaluate(test_predictions) \n",
    "testing_precision = precision_eveluator.evaluate(test_predictions) \n",
    "testing_recall = recall_eveluator.evaluate(test_predictions) \n",
    "testing_f1 = f1_eveluator.evaluate(test_predictions) \n",
    "\n",
    "print(f\"Testing accuracy : {testing_accuracy}\")\n",
    "print(f\"Testing precision : {testing_precision}\")\n",
    "print(f\"Testing recall : {testing_recall}\")\n",
    "print(f\"Testing F1 score : {testing_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics\n",
    "\n",
    "# CM (confusion matrix)\n",
    "\n",
    "# accuracy = number of crroect predictions / total number of prediction\n",
    "# precision = true pos / true pos + false pos\n",
    "# recall = true pos / true pos + false neg\n",
    "# f1 score = 2 * (precision * recall / precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----+\n",
      "|features                                                      |label|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|(83,[7,11,78,79,80,81,82],[1.0,1.0,-7.0,-5.0,935.0,12.0,12.0])|0    |\n",
      "|(83,[0,29,78,79,80,81,82],[1.0,1.0,5.0,5.0,1505.0,1.0,17.0])  |1    |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data_transformed.select(\"features\", \"label\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carrier_encoded',\n",
       " 'dest_encoded',\n",
       " 'dep_delay',\n",
       " 'arr_delay',\n",
       " 'arr_time',\n",
       " 'month',\n",
       " 'plane_age']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+---+--------+---------+--------+---------+-------+------+------+----+--------+--------+----+------+----------+--------------------+------------+--------+-------+-----+---------+---------+-------+-----+-------------+---------------+----------+---------------+--------------------+\n",
      "|tailnum|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|flight|origin|dest|air_time|distance|hour|minute|manuf_year|                type|manufacturer|   model|engines|seats|   engine|plane_age|is_late|label|carrier_index|carrier_encoded|dest_index|   dest_encoded|            features|\n",
      "+-------+----+-----+---+--------+---------+--------+---------+-------+------+------+----+--------+--------+----+------+----------+--------------------+------------+--------+-------+-----+---------+---------+-------+-----+-------------+---------------+----------+---------------+--------------------+\n",
      "| N846VA|2023|   12|  8|     658|       -7|     935|       -5|     VX|  1780|   SEA| LAX|     132|     954|   6|    58|      2011|Fixed wing multi ...|      AIRBUS|A320-214|      2|  182|Turbo-fan|       12|  false|    0|          7.0| (10,[7],[1.0])|       1.0| (68,[1],[1.0])|(83,[7,11,78,79,8...|\n",
      "| N559AS|2023|    1| 22|    1040|        5|    1505|        5|     AS|   851|   SEA| HNL|     360|    2677|  10|    40|      2006|Fixed wing multi ...|      BOEING| 737-890|      2|  149|Turbo-fan|       17|   true|    1|          0.0| (10,[0],[1.0])|      19.0|(68,[19],[1.0])|(83,[0,29,78,79,8...|\n",
      "+-------+----+-----+---+--------+---------+--------+---------+-------+------+------+----+--------+--------+----+------+----------+--------------------+------------+--------+-------+-----+---------+---------+-------+-----+-------------+---------------+----------+---------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_data_transformed.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data or Live Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "# from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.tuning import CrossValidatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the pipeline model and the cross-validated model\n",
    "\n",
    "# Load the fitted pipeline model\n",
    "pipeline_model = PipelineModel.load(\"model-artifacts-01/fitted_pipeline_model\")\n",
    "\n",
    "# Load the cross-validated model\n",
    "cv_model = CrossValidatorModel.load(\"model-artifacts-01/cv_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input data or live data \n",
    "input_data = Row(\n",
    "    carrier=\"AS\",\n",
    "    dest=\"HNL\",\n",
    "    dep_delay=5,\n",
    "    arr_delay=5,\n",
    "    arr_time=1505,\n",
    "    month=1,\n",
    "    plane_age=17\n",
    ")\n",
    "\n",
    "# Create a Spark DataFrame from the input data\n",
    "input_df = spark.createDataFrame([input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+---------+--------+-----+---------+\n",
      "|carrier|dest|dep_delay|arr_delay|arr_time|month|plane_age|\n",
      "+-------+----+---------+---------+--------+-----+---------+\n",
      "|     AS| HNL|        5|        5|    1505|    1|       17|\n",
      "+-------+----+---------+---------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transformed = pipeline_model.transform(input_df)\n",
    "predictions = cv_model.transform(input_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+----------+---------------------------------------+\n",
      "|features                                                    |prediction|probability                            |\n",
      "+------------------------------------------------------------+----------+---------------------------------------+\n",
      "|(83,[0,29,78,79,80,81,82],[1.0,1.0,5.0,5.0,1505.0,1.0,17.0])|1.0       |[0.2226147759073654,0.7773852240926347]|\n",
      "+------------------------------------------------------------+----------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\", \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
